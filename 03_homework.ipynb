{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c678e33-7efc-47da-bd84-890daf4b5beb",
   "metadata": {},
   "source": [
    "# Задание 1 (5 балла)\n",
    "\n",
    "Имплементируйте алгоритм Леска (описание есть в семинаре) и оцените качество его работы на датасете `data/corpus_wsd_50k.txt`\n",
    "\n",
    "В качестве метрики близости вы должны попробовать два подхода:\n",
    "\n",
    "1) Jaccard score на множествах слов (определений и контекста)\n",
    "2) Cosine distance на эмбедингах sentence_transformers\n",
    "\n",
    "В качестве метрики используйте accuracy (% правильных ответов). Предсказывайте только многозначные слова в датасете\n",
    "\n",
    "Контекст вы можете определить самостоятельно (окно вокруг целевого слова или все предложение). Также можете поэкспериментировать с предобработкой для обоих методов."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "В качестве контекста было выбрано предложение, в котором находится слово.\n",
    "\n",
    "Окончательный вариант решения, который не выдает ошибок, но в google collab время выполнения этого кода около 4х часов:"
   ],
   "id": "2df6dde939dff4e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import codecs\n",
    "import nltk\n",
    "from nltk.corpus.reader import Synset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "!mkdir data\n",
    "!wget https://github.com/mannefedov/compling_nlp_hse_course/raw/master/data/corpus_wsd_50k.txt.zip -P data\n",
    "!unzip -o data/corpus_wsd_50k.txt.zip -d data/\n",
    "\n",
    "!python -m pip install torch torchvision torchaudio\n",
    "!python -m pip install sentence_transformers transformers accelerate -U\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def jaccard_score(definition: set, context: set):\n",
    "    intersection = definition & context\n",
    "    union = definition | context\n",
    "    jaccard = len(intersection) / len(union)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "def cosine_distance_score(definition, context):\n",
    "    definition_embedding = embed(' '.join(definition))\n",
    "    context_embedding = embed(' '.join(context))\n",
    "    cosine_distance = cosine_similarity(context_embedding.reshape(1, -1), definition_embedding.reshape(1, -1))\n",
    "    return cosine_distance\n",
    "\n",
    "\n",
    "def lesk_algorithm(context: str, word: str) -> tuple[Synset | None, Synset | None]:\n",
    "    synsets = wn.synsets(word)\n",
    "    context_set = set(context.split())\n",
    "\n",
    "    jaccard_best_synset = None\n",
    "    cosine_dist_best_synset = None\n",
    "    jaccard_best_score = 0\n",
    "    cosine_dist_best_score = 0\n",
    "\n",
    "    for synset in synsets:\n",
    "        definition = set(synset.definition().split())\n",
    "        jaccard = jaccard_score(definition, context_set)\n",
    "        cosine_dist = cosine_distance_score(definition, context_set)\n",
    "        if jaccard > jaccard_best_score:\n",
    "            jaccard_best_synset = synset\n",
    "            jaccard_best_score = jaccard\n",
    "        if cosine_dist > cosine_dist_best_score:\n",
    "            cosine_dist_best_synset = synset\n",
    "            cosine_dist_best_score = cosine_dist\n",
    "\n",
    "    return jaccard_best_synset, cosine_dist_best_synset\n",
    "\n",
    "\n",
    "def accuracy_metric(jaccard_cosine_tuple: tuple[Synset | None, Synset | None], original_synset: Synset):\n",
    "    jaccard_is_correct = 0\n",
    "    cosine_is_correct = 0\n",
    "    if jaccard_cosine_tuple[0] is not None and jaccard_cosine_tuple[0].name() == original_synset.name():\n",
    "        jaccard_is_correct += 1\n",
    "    if jaccard_cosine_tuple[1] is not None and jaccard_cosine_tuple[1].name() == original_synset.name():\n",
    "        cosine_is_correct += 1\n",
    "\n",
    "    return jaccard_is_correct, cosine_is_correct\n",
    "\n",
    "\n",
    "corpus_wsd = []\n",
    "file = codecs.open('data/corpus_wsd_50k.txt', 'r', 'utf_8_sig')\n",
    "corpus = file.read().split('\\n\\n')\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])\n",
    "file.close()\n",
    "\n",
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# модель эмбеддинга\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embed = model.encode\n",
    "\n",
    "sentences_data = []\n",
    "for corpus_sentence in corpus_wsd:\n",
    "    sentence = ''\n",
    "    polysemous_sense = ''\n",
    "    polysemous_word = ''\n",
    "    for corpus_word in corpus_sentence:\n",
    "        if len(corpus_word) < 3:\n",
    "            break\n",
    "\n",
    "        sense, _, word = corpus_word\n",
    "        if '%' in sense and not polysemous_sense:\n",
    "            polysemous_sense = sense\n",
    "            polysemous_word = word\n",
    "        else:\n",
    "            sentence += ''.join(word) + ' '\n",
    "\n",
    "    sentences_data.append((sentence, polysemous_sense, polysemous_word))\n",
    "\n",
    "total = len(corpus_wsd)\n",
    "jaccard_correct = 0\n",
    "cosine_correct = 0\n",
    "\n",
    "for sentence_data in sentences_data:\n",
    "    sentence, sense, word = sentence_data\n",
    "    if not sense:\n",
    "        continue\n",
    "    jaccard_cosine_tuple = lesk_algorithm(sentence, word)\n",
    "\n",
    "    original_synset = wn.lemma_from_key(sense).synset()\n",
    "    jaccard, cosine = accuracy_metric(jaccard_cosine_tuple, original_synset)\n",
    "    jaccard_correct += jaccard\n",
    "    cosine_correct += cosine\n",
    "\n",
    "jaccard_metric = jaccard_correct / total * 100\n",
    "cosine_metric = cosine_correct / total * 100\n",
    "\n",
    "print('jaccard ' + str(jaccard_metric) + ' cosine ' + str(cosine_metric))"
   ],
   "id": "6e8e64dd6f4a66ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Изначальный код до дорабатывания его в google collab, который не считает accuracy, но выдает jaccard_score и cosine_distance_score для одного слова, если вводить его вручную:",
   "id": "686d8873167edf03"
  },
  {
   "cell_type": "code",
   "id": "5814a100-9ba8-4787-b0ac-73fa657a3fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:29:50.428759Z",
     "start_time": "2024-10-07T16:29:50.421502Z"
    }
   },
   "source": [
    "import codecs\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:29:52.627704Z",
     "start_time": "2024-10-07T16:29:52.344854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ],
   "id": "9b32f514f2d75ac4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\eliza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eliza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\eliza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:30:00.490430Z",
     "start_time": "2024-10-07T16:29:57.678979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_wsd = []\n",
    "file = codecs.open('data/corpus_wsd_50k.txt', 'r', 'utf_8_sig')\n",
    "corpus = file.read().split('\\n\\n')\n",
    "for sent in corpus:\n",
    "    corpus_wsd.append([s.split('\\t') for s in sent.split('\\n')])\n",
    "file.close()"
   ],
   "id": "44fd4dfb2b477c4f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:30:09.823460Z",
     "start_time": "2024-10-07T16:30:07.378262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "english_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "# модель эмбеддинга\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embed = model.encode"
   ],
   "id": "25cabcdb06f5e2e6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliza\\PycharmProjects\\compling_nlp_hse_course\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:37:12.098141Z",
     "start_time": "2024-10-07T16:37:12.088574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sentence_and_word(corpus_wsd):\n",
    "    sentences_and_words = []\n",
    "\n",
    "    for sentence_data in corpus_wsd:\n",
    "        # Собираем предложение из всех слов в sentence_data\n",
    "        # sentence = ' '.join([word_data[2] for word_data in sentence_data])\n",
    "\n",
    "        # Для каждого слова в предложении проверяем, многозначное оно или нет\n",
    "        for word_data in sentence_data:\n",
    "            sense, lemma, word = word_data\n",
    "            if '%' in sense:  # Если это многозначное слово\n",
    "                # Добавляем к результатам предложение и это многозначное слово\n",
    "                sentences_and_words.append(sentence_data, word, sense)\n",
    "\n",
    "    return sentences_and_words"
   ],
   "id": "68b2361694e2e534",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:31:15.028654Z",
     "start_time": "2024-10-07T16:31:15.020386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Эта функция разбивает на токены\n",
    "def preprocess(text: list):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [token for token in tokens if token.isalpha() and token not in english_stopwords]\n",
    "    return ' '.join(tokens)"
   ],
   "id": "3a30ad3f144f0168",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:31:16.551759Z",
     "start_time": "2024-10-07T16:31:16.542039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def jaccard_score(definition: set, context: set):\n",
    "    intersection = definition & context\n",
    "    union = definition | context\n",
    "    jaccard = len(intersection) / len(union)\n",
    "    return jaccard"
   ],
   "id": "dd6cd705fd51b3db",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T17:22:25.452833Z",
     "start_time": "2024-10-07T17:22:25.439657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def cosine_distance_score(definition, context):\n",
    "    # Надо превратить определение и контекст в эмбеддинги и посчитать их\n",
    "    definition_embedding = embed(' '.join(definition))\n",
    "    context_embedding = embed(' '.join(context))\n",
    "    cosine_distance = cosine_similarity(context_embedding.reshape(1, -1), definition_embedding.reshape(1, -1))\n",
    "    return cosine_distance"
   ],
   "id": "c37a2aebde6fb361",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T17:22:27.420431Z",
     "start_time": "2024-10-07T17:22:27.413337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lesk_algorithm(context: str, word: str):\n",
    "    synsets = wn.synsets(word)\n",
    "    if len(synsets) <= 1:\n",
    "        return 'Not polysemous word'\n",
    "    \n",
    "    context_set = set(context.split())\n",
    "    \n",
    "    result = []\n",
    "    for synset in synsets:\n",
    "        definition = set(synset.definition().split())\n",
    "        jaccard = jaccard_score(definition, context_set)\n",
    "        cosine = cosine_distance_score(definition, context_set)\n",
    "        print('jaccard: ' + str(jaccard) + ' cosine: ' + str(cosine))"
   ],
   "id": "45d28831b76681ea",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:35:21.578968Z",
     "start_time": "2024-10-07T16:35:21.550492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def accuracy_metric(corpus_wsd):\n",
    "#     sentences_and_words = sentence_and_word(corpus_wsd)\n",
    "# \n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "# \n",
    "#     for sentence_data, word, true_sense in sentences_and_words:\n",
    "#         # Применяем алгоритм Леска\n",
    "#         predicted_sense = lesk_algorithm(sentence_data, word)\n",
    "# \n",
    "#         if predicted_sense and predicted_sense.name() == true_sense:\n",
    "#             correct += 1\n",
    "#         total += 1\n",
    "# \n",
    "#     return correct / total * 100 if total > 0 else 0"
   ],
   "id": "f01eb0ae511c6374",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T17:22:33.234277Z",
     "start_time": "2024-10-07T17:22:31.395405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# accuracy = accuracy_metric(corpus_wsd)\n",
    "# print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "sentence_list = []\n",
    "for item in corpus_wsd:\n",
    "    sentence = ''\n",
    "    word = ''\n",
    "    for word_list in item:\n",
    "        word = ''.join(word_list[2])\n",
    "        sentence += word + ' '\n",
    "    sentence_list.append(sentence)\n",
    "    break\n",
    "        \n",
    "word = 'long'\n",
    "predicted_sense = lesk_algorithm(sentence_list[0], word)\n"
   ],
   "id": "4e831040db6462b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaccard: 0.0 cosine: [[0.09104943]]\n",
      "jaccard: 0.029411764705882353 cosine: [[0.12430339]]\n",
      "jaccard: 0.034482758620689655 cosine: [[0.0590357]]\n",
      "jaccard: 0.043478260869565216 cosine: [[0.01143938]]\n",
      "jaccard: 0.0 cosine: [[0.13970378]]\n",
      "jaccard: 0.038461538461538464 cosine: [[-0.0247157]]\n",
      "jaccard: 0.08333333333333333 cosine: [[0.08094941]]\n",
      "jaccard: 0.0 cosine: [[0.13382748]]\n",
      "jaccard: 0.047619047619047616 cosine: [[0.18524656]]\n",
      "jaccard: 0.0 cosine: [[0.03750885]]\n",
      "jaccard: 0.0 cosine: [[0.11933612]]\n",
      "jaccard: 0.0 cosine: [[0.10371695]]\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "id": "74454823",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39efde9a-af0b-4c94-bfd0-249e7054562f",
   "metadata": {},
   "source": [
    "# Задание 2 (5 балла)\n",
    "Попробуйте разные алгоритмы кластеризации на датасете - `https://github.com/nlpub/russe-wsi-kit/blob/initial/data/main/wiki-wiki/train.csv`\n",
    "\n",
    "Используйте код из семинара как основу. Используйте ARI как метрику качества.\n",
    "\n",
    "Попробуйте все 4 алгоритма кластеризации, про которые говорилось на семинаре. Для каждого из алгоритмов попробуйте настраивать гиперпараметры (посмотрите их в документации). Прогоните как минимум 5 экспериментов (не обязательно успешных) с разными параметрами на каждый алгоритме кластеризации и оцените: качество кластеризации, скорость работы, интуитивность параметров.\n",
    "\n",
    "Помимо этого также выберите 1 дополнительный алгоритм кластеризации отсюда - https://scikit-learn.org/stable/modules/clustering.html , опишите своими словами принцип его работы  и проделайте аналогичные эксперименты. "
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:39:15.527161Z",
     "start_time": "2024-10-13T11:39:15.521751Z"
    }
   },
   "cell_type": "code",
   "source": "import time",
   "id": "9e285d41cb4304bf",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "d59bef3e-1af7-4ce2-b43a-dfef282050f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:39:19.725625Z",
     "start_time": "2024-10-13T11:39:17.166206Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:39:21.456540Z",
     "start_time": "2024-10-13T11:39:20.946569Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_csv('https://raw.githubusercontent.com/nlpub/russe-wsi-kit/initial/data/main/wiki-wiki/train.csv', sep='\\t')",
   "id": "e442401bcd073ad5",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:39:24.523297Z",
     "start_time": "2024-10-13T11:39:24.503441Z"
    }
   },
   "cell_type": "code",
   "source": "df.head(100)",
   "id": "bf17217506ea4dd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    context_id   word  gold_sense_id  predict_sense_id  \\\n",
       "0            1  замок              1               NaN   \n",
       "1            2  замок              1               NaN   \n",
       "2            3  замок              1               NaN   \n",
       "3            4  замок              1               NaN   \n",
       "4            5  замок              1               NaN   \n",
       "..         ...    ...            ...               ...   \n",
       "95          96  замок              1               NaN   \n",
       "96          97  замок              1               NaN   \n",
       "97          98  замок              1               NaN   \n",
       "98          99  замок              1               NaN   \n",
       "99         100  замок              1               NaN   \n",
       "\n",
       "                    positions  \\\n",
       "0                0-5, 339-344   \n",
       "1       11-16, 17-22, 188-193   \n",
       "2                     299-304   \n",
       "3                     111-116   \n",
       "4            134-139, 262-267   \n",
       "..                        ...   \n",
       "95  163-168, 213-218, 364-369   \n",
       "96           221-226, 276-281   \n",
       "97        0-5, 16-21, 179-184   \n",
       "98                    232-237   \n",
       "99     5-10, 150-155, 289-294   \n",
       "\n",
       "                                              context  \n",
       "0   замок владимира мономаха в любече . многочисле...  \n",
       "1   шильонский замок замок шильйон ( ) , известный...  \n",
       "2   проведения архитектурно - археологических рабо...  \n",
       "3   топи с . , л . белокуров легенда о завещании м...  \n",
       "4   великий князь литовский гедимин после успешной...  \n",
       "..                                                ...  \n",
       "95  без каминов и очагов . у входа в башню было по...  \n",
       "96  v . в том сражении шотландцы потерпели сокруши...  \n",
       "97  замок данноттар замок данноттар ( ) расположен...  \n",
       "98  . благодаря поэме байрона заключение бонивара ...  \n",
       "99  года замок утратил свое военное значение , так...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_id</th>\n",
       "      <th>word</th>\n",
       "      <th>gold_sense_id</th>\n",
       "      <th>predict_sense_id</th>\n",
       "      <th>positions</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-5, 339-344</td>\n",
       "      <td>замок владимира мономаха в любече . многочисле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11-16, 17-22, 188-193</td>\n",
       "      <td>шильонский замок замок шильйон ( ) , известный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299-304</td>\n",
       "      <td>проведения архитектурно - археологических рабо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111-116</td>\n",
       "      <td>топи с . , л . белокуров легенда о завещании м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>134-139, 262-267</td>\n",
       "      <td>великий князь литовский гедимин после успешной...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163-168, 213-218, 364-369</td>\n",
       "      <td>без каминов и очагов . у входа в башню было по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221-226, 276-281</td>\n",
       "      <td>v . в том сражении шотландцы потерпели сокруши...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-5, 16-21, 179-184</td>\n",
       "      <td>замок данноттар замок данноттар ( ) расположен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>232-237</td>\n",
       "      <td>. благодаря поэме байрона заключение бонивара ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>замок</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5-10, 150-155, 289-294</td>\n",
       "      <td>года замок утратил свое военное значение , так...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:39:27.326837Z",
     "start_time": "2024-10-13T11:39:27.319520Z"
    }
   },
   "cell_type": "code",
   "source": "grouped_df = df.groupby('word')[['word', 'context', 'gold_sense_id']]",
   "id": "4ed81cbb650f08e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:41.348815Z",
     "start_time": "2024-10-14T17:41:41.335118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, AffinityPropagation, AgglomerativeClustering, OPTICS\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ],
   "id": "598e60b1e04031f3",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:40:01.388744Z",
     "start_time": "2024-10-13T11:39:50.557116Z"
    }
   },
   "cell_type": "code",
   "source": "from sentence_transformers import SentenceTransformer",
   "id": "53abdb5038bf54e5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliza\\PycharmProjects\\compling_nlp_hse_course\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:40:40.924059Z",
     "start_time": "2024-10-13T11:40:03.761191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "embed = model.encode"
   ],
   "id": "c3c540cfbdbece81",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84e10dd8fb9b4fb0937c04e694f03d41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliza\\PycharmProjects\\compling_nlp_hse_course\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\eliza\\.cache\\huggingface\\hub\\models--sentence-transformers--all-mpnet-base-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de6af1f2915c40bdb6afe9ca30cd591f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd443cdb6f684a8184c8f4d51e3a361f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caf60552d7394f1f9395a91d4f7b6099"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5c1cf83fd9645a7aeaefe22689539c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16fbf2b07c35409d9f1d7ee19cafb741"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0a83e5a4660459cb6dfc15536c42404"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82350b94fc2246eeba65b86c44b41d8f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f4f438cfeaa4f0bb9c720b960b5a3c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0013567944204bd6bf2783402baca741"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eliza\\PycharmProjects\\compling_nlp_hse_course\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c0de4834a174d66a17fa69889880e33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Kmeans",
   "id": "b2c0b0b9c7144f91"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T21:52:54.246872Z",
     "start_time": "2024-10-11T21:50:08.931498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = KMeans(7)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "a259ea8d8cd808a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.11446408920413326\n",
      "Время выполнения: 165.31 секунд\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T21:57:07.824875Z",
     "start_time": "2024-10-11T21:54:38.114608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    # выбираем один из алгоритмов\n",
    "    # cluster = AffinityPropagation(damping=0.9)\n",
    "    cluster = KMeans(2)\n",
    "#     cluster = DBSCAN(min_samples=1, eps=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "eecd7edc81f874a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06806698150265096\n",
      "Время выполнения: 149.71 секунд\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:00:02.570749Z",
     "start_time": "2024-10-11T21:57:31.477066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    # выбираем один из алгоритмов\n",
    "    # cluster = AffinityPropagation(damping=0.9)\n",
    "    cluster = KMeans(4)\n",
    "#     cluster = DBSCAN(min_samples=1, eps=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "16bb50cebf176ed0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07350251244932049\n",
      "Время выполнения: 151.09 секунд\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:02:52.985415Z",
     "start_time": "2024-10-11T22:00:24.081294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    # выбираем один из алгоритмов\n",
    "    # cluster = AffinityPropagation(damping=0.9)\n",
    "    cluster = KMeans(10)\n",
    "#     cluster = DBSCAN(min_samples=1, eps=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "1be2e4d3a1050410",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06485713902036974\n",
      "Время выполнения: 148.89 секунд\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:05:54.864919Z",
     "start_time": "2024-10-11T22:03:23.421255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    # выбираем один из алгоритмов\n",
    "    # cluster = AffinityPropagation(damping=0.9)\n",
    "    cluster = KMeans(5)\n",
    "#     cluster = DBSCAN(min_samples=1, eps=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "e55ef5259e0b9fbc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038730501929247436\n",
      "Время выполнения: 151.44 секунд\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Самый лучший результат для этой метрики при параметре 7 (0.11446408920413326), при этом алгоритм работает самое долгое время, по сравнению с результатами при других параметрах. Однако я несколько раз запускала алгоритм с одинаковым параметром и каждый раз результаты были разные. Вероятно, это происходит потому, что при каждом запуске центроиды выбираются рандомно. Это так же прибавляет сложности поиску оптимального параметра. Не совсем интуитивно понятно, какое количество кластеров выбрать оптимальным, так как результаты и при небольшом количестве кластеров (2), и при большом количестве кластеров (10) примерно одинаковые (0.06806698150265096 vs 0.06485713902036974). При этом самый худший результат получился при параметре 5 (0.038730501929247436), хотя при параметрах 4 (0.07350251244932049) и 3 (0.07963918459393977 - взят из лекции), результаты уже лучше. Это опять же объясняется рандомным выбором центроидов.\n",
    "\n",
    "Если учитывать результаты параметров, которые отсутствуют в ответе, но были выполнены, то с увеличением количества кластеров (начиная от 9-10), результаты кластеризации становятся хуже, так же как и если брать результаты кластеризации при параметре 1 и 2. В одной из итераций результат для параметра 2 оказался примерно 0.00298, а для параметра 1 вообще 0.0."
   ],
   "id": "56b7f81806bf563b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### DBSCAN",
   "id": "9e186f5756c67151"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:29:00.243072Z",
     "start_time": "2024-10-11T22:26:29.444204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=1, eps=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "444889d31530a669",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.001053019960000099\n",
      "Время выполнения: 150.77 секунд\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T22:43:51.740607Z",
     "start_time": "2024-10-11T22:41:20.537285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=5, eps=0.3)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "cf0e9070a5119baf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: -0.02349153051130162\n",
      "Время выполнения: 151.19 секунд\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T11:44:49.890394Z",
     "start_time": "2024-10-13T11:42:09.553485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=4, eps=0.68)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "4a85da4991a35916",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.07402644018324375\n",
      "Время выполнения: 160.32 секунд\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:40:29.925489Z",
     "start_time": "2024-10-13T19:37:56.761303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=8, eps=0.5)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "75a07ae5431cc9d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.012476507850342128\n",
      "Время выполнения: 153.11 секунд\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:48:03.241287Z",
     "start_time": "2024-10-13T19:45:13.117602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=1, eps=0.52)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "2f533314c0154a60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.11842783110378406\n",
      "Время выполнения: 170.10 секунд\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:51:14.006742Z",
     "start_time": "2024-10-13T19:48:39.772749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=2, eps=0.52)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "78279edeef39430c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.10894038562828764\n",
      "Время выполнения: 154.23 секунд\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:55:18.379292Z",
     "start_time": "2024-10-13T19:52:44.827583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=1, eps=0.61)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "13106402608b2068",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.13372367481954406\n",
      "Время выполнения: 153.53 секунд\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T19:58:08.869368Z",
     "start_time": "2024-10-13T19:55:37.109109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = DBSCAN(min_samples=2, eps=0.61)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "a1f3940868123658",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.13259354738443666\n",
      "Время выполнения: 151.75 секунд\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Для этого датасета при использовании метрики DBSCAN наиболее точные результаты получаются при уменьшении количества объектов и радиусе между 0.52 и 0.61. Также в последних тестах, где сравниваются показатели при количестве объектов 1 и 2 и радиусе 0.51 и 0.61 (и их комбинации), можно заметить, что для более точного результата требуется большее количество времени, а также при уменьшении минимального количества объектов времени тоже затрачивается больше. Настройка параметров интуитивно понятна, особым плюсом стоит здесь отметить то, что метрика сама определяет количество кластеров на основе плотности. Самый сложный момент - это понять, какой радиус должен быть и сколько минимальных объектов должно быть.\n",
    "\n",
    "DBSCAN выдает более точные результаты по сравнению с Kmeans для этого датасета, но при этом увеличивается скорость работы программы. Более точный результат кластеризации скорее всего получается потому, что данные имеют сложную форму, с которой лучше работает DBSCAN, а не сферическую, на что нацелен Kmeans."
   ],
   "id": "1211bba54bf149e0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Affinity Propagation",
   "id": "1defc3abcaabf1a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-13T21:04:23.417780Z",
     "start_time": "2024-10-13T21:01:51.404239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AffinityPropagation(damping=0.9)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "ecc7f60306ec6b13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.05297560306165972\n",
      "Время выполнения: 151.98 секунд\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:46:09.198238Z",
     "start_time": "2024-10-14T14:43:05.739515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AffinityPropagation(damping=0.52)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "5bb8c03a5c015126",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.042740969848549505\n",
      "Время выполнения: 183.41 секунд\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:49:30.801423Z",
     "start_time": "2024-10-14T14:46:47.995780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AffinityPropagation(damping=0.7)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "51a4f552498a7c53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.04150923434928373\n",
      "Время выполнения: 162.80 секунд\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Для Affinity Propagation тесты с изменением параметра damping выдавали результат не выше 0.05297560306165972, поэтому захотелось попробовать настроить preference.\n",
   "id": "e4e22b5c2d9a720e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T14:56:40.206985Z",
     "start_time": "2024-10-14T14:54:06.954102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AffinityPropagation(preference=10, damping=0.52)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "e7faae12b7b8952b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.0\n",
      "Время выполнения: 153.23 секунд\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:07:16.769482Z",
     "start_time": "2024-10-14T15:04:24.460179Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AffinityPropagation(preference=-50, damping=0.9)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "78678aeb4a95443e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.0\n",
      "Время выполнения: 172.30 секунд\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "В Jupiter Notebook при добавлении параметра preference метрика выдает 0.0, в Google Collab выдавалось при любых damping и preference значение 0.05297560306165972.",
   "id": "15724f53a92114ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "При использовании Affinity Propagation время работы программы большее, чем при использовании Kmeans и DBSCAN. Точность кластеризации так же ниже. Возможно, датасету нужна дополнительная предобработка, так как все предыдущие метрики тоже не выдавали очень точных результатов (близких к 1).\n",
    "\n",
    "Немного более точные результаты выдавались при параметре damping стремящемся к 1, этот параметр достаточно понятен.\n",
    "В теории параметр preference при низких значениях должен был уменьшать количество кластеров, а при больших значениях, наоборот, увеличивать. Но не совсем интуитивно понятно, какое количество кластеров оптимальное (от какого значения надо уменьшать или увеличивать количество кластеров)."
   ],
   "id": "676e033de51b018a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Agglomerative clustering",
   "id": "57f46de2274e04ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:51:43.939218Z",
     "start_time": "2024-10-14T15:48:48.401694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=2)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "9157c88b46ec95e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: -0.011976265536517934\n",
      "Время выполнения: 175.53 секунд\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T15:55:08.340380Z",
     "start_time": "2024-10-14T15:52:12.144419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=8)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "ca28d61280c1041d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.057641599566266404\n",
      "Время выполнения: 176.19 секунд\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:20:37.266137Z",
     "start_time": "2024-10-14T16:17:59.049601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "f08be65ca517d114",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.06308052666462462\n",
      "Время выполнения: 158.21 секунд\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:07:11.240147Z",
     "start_time": "2024-10-14T16:04:16.625885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=5)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "ead4a02b1d1b788c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.03379296274962468\n",
      "Время выполнения: 174.61 секунд\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:10:18.686545Z",
     "start_time": "2024-10-14T16:07:35.258125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=20)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "2927ea93b9b74120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.04406294885576405\n",
      "Время выполнения: 163.42 секунд\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "При использовании только параметра количества кластеров для Agglomerative clustering результаты кластеризации не очень точные. Лучший результат выдается при количестве кластеров 9.\n",
    "\n",
    "Попробуем косинусное расстояние в качестве метрики расстояния (вместо базового евклидового расстояния), для этого еще нужно заменить параметр linkage (который по умолчанию равен ward)"
   ],
   "id": "9a95220aac1132ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:28:12.547708Z",
     "start_time": "2024-10-14T16:25:21.910026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9, metric=\"cosine\", linkage='average')\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "fc3488ce8ce6461",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.1245453538775664\n",
      "Время выполнения: 170.63 секунд\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Результат уже получается намного лучше, попробуем другие параметры linkage.",
   "id": "9b01968ebd8b811e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:36:52.039051Z",
     "start_time": "2024-10-14T16:34:01.598529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9, metric=\"cosine\", linkage='complete')\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "780e3a5737aa302",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.06987009143297748\n",
      "Время выполнения: 170.43 секунд\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:41:57.836880Z",
     "start_time": "2024-10-14T16:39:07.076317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9, metric=\"cosine\", linkage='single')\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "f3fb5824630d6b10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.15965864432739085\n",
      "Время выполнения: 170.75 секунд\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:50:45.164921Z",
     "start_time": "2024-10-14T16:47:57.577311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9, metric=\"manhattan\", linkage='average')\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "f8f1ec8ac54de71d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.11781181319772398\n",
      "Время выполнения: 167.58 секунд\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:55:13.158463Z",
     "start_time": "2024-10-14T16:52:16.713143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9, metric=\"manhattan\", linkage='complete')\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "1494cf7820a6973d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.046212305114339\n",
      "Время выполнения: 176.44 секунд\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T16:58:59.157006Z",
     "start_time": "2024-10-14T16:56:10.138913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = AgglomerativeClustering(n_clusters=9, metric=\"manhattan\", linkage='single')\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "9d47750dd8bec357",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.15965864432739085\n",
      "Время выполнения: 169.01 секунд\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Наилучший результат кластеризации для Agglomerative clustering получается при использовании параметров (n_clusters=9, metric=\"manhattan\", linkage='single') и (n_clusters=9, metric=\"cosine\", linkage='single'). Время выполнения программ выше, чем у предыдущих метрик, но при этом эта метрика выдает лучшие результаты кластеризации.\n",
    "Параметры интуитивно понятны, главное - разобраться с количеством кластеров. "
   ],
   "id": "1ea209880e4e3648"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OPTICS",
   "id": "825310c0147e7b02"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "OPTICS - алгорит кластеризации, который поход на DBSCAN, однако, в отличие от DBSCAN, OPTICS позволяет выявлять кластеры с различной плотностью. Этот алгоритм упорядочивает точки данных по их плотностям, строя так называемый \"reachability plot\" (график достижимости), который можно использовать для идентификации кластеров с разной плотностью.\n",
    "\n",
    "Основные параметры OPTICS:\n",
    "min_samples: Минимальное количество точек, которые должны быть в радиусе eps от центральной точки, чтобы она считалась \"ядром\".\n",
    "max_eps: Максимальное расстояние между двумя точками для их объединения в один кластер. При уменьшении максимального расстояния время работы программы будет уменьшаться.\n",
    "xi: Порог, определяющий падение плотности, при котором OPTICS считает, что достигнут конец одного кластера и начинается другой.\n",
    "metric: Расстояние, используемое для вычисления плотности (по умолчанию — minkowski)."
   ],
   "id": "c38489e3c9bca1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:44:32.773497Z",
     "start_time": "2024-10-14T17:41:50.187667Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=5, xi=0.05, min_cluster_size=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "bfd2655c8e9f7bab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: -0.005376253758977646\n",
      "Время выполнения: 162.57 секунд\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:49:47.631665Z",
     "start_time": "2024-10-14T17:47:09.851466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=1.0, xi=0.05, min_cluster_size=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "2bdfea40d03c00c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.0\n",
      "Время выполнения: 157.78 секунд\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:52:53.227818Z",
     "start_time": "2024-10-14T17:50:13.373733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=2, xi=0.05, min_cluster_size=0.1)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "16916eb91de69209",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: -0.005376253758977646\n",
      "Время выполнения: 159.83 секунд\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T18:48:04.615668Z",
     "start_time": "2024-10-14T18:45:37.516207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=2, xi=0.52, min_cluster_size=None)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "57ea5db69cfc54c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.016982890179909997\n",
      "Время выполнения: 147.09 секунд\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:04:36.609205Z",
     "start_time": "2024-10-14T19:02:07.367981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=2, xi=0.61, min_cluster_size=None)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "c2215337ffb823db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.03095171203962383\n",
      "Время выполнения: 149.22 секунд\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:20:28.528861Z",
     "start_time": "2024-10-14T19:18:00.022158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=2, xi=0.79, min_cluster_size=None)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "5a5ffe46642602c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.07676424673416805\n",
      "Время выполнения: 148.50 секунд\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:43:35.221121Z",
     "start_time": "2024-10-14T19:41:09.244390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=2, xi=0.79, min_cluster_size=2)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "e06dad998801956a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.07676424673416805\n",
      "Время выполнения: 145.96 секунд\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T19:47:01.497786Z",
     "start_time": "2024-10-14T19:44:32.495816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "start_time = time.time()\n",
    "\n",
    "ARI = []\n",
    "\n",
    "for key, _ in grouped_df:\n",
    "    # вытаскиваем контексты\n",
    "    texts = grouped_df.get_group(key)['context'].values\n",
    "\n",
    "    # создаем пустую матрицу для векторов \n",
    "    X = np.zeros((len(texts), 768))\n",
    "\n",
    "    # переводим тексты в векторы и кладем в матрицу\n",
    "    for i, text in enumerate(texts):\n",
    "        X[i] = embed(text)\n",
    "\n",
    "    cluster = OPTICS(min_samples=2, xi=0.79, min_cluster_size=3)\n",
    "    \n",
    "    cluster.fit(X)\n",
    "    labels = np.array(cluster.labels_)+1 \n",
    "\n",
    "    # расчитываем метрику для отдельного слова\n",
    "    ARI.append(adjusted_rand_score(grouped_df.get_group(key)['gold_sense_id'], labels))\n",
    "    \n",
    "print(\"Метрика ARI:\", np.mean(ARI)) # усредненная метрика\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Время выполнения: {elapsed_time:.2f} секунд\")"
   ],
   "id": "60e075667ce5119d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика ARI: 0.01654322779148901\n",
      "Время выполнения: 148.99 секунд\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Время работы программы с использованием OPTICS меньше, чем при использовании Agglomerative clustering и Affinity Propagation.\n",
    "Лучший результат получается при минимальном количестве экземпляров 2 и пороге падения плотности (xi) 0.79. При этом минимальное количество кластеров должно быть либо равно 2м, либо None. При увеличении количества кластеров результат ухудшается. Наилучший результат кластеризации все еще выдает Agglomerative clustering. DBSCAN, на которую похожа модель OPTICS, также выдает более точные результаты.\n",
    "Также довольно сложно подбирать параметры."
   ],
   "id": "7f7bc1c60d5665a2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
